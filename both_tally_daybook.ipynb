{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkar-salunke/accounts/blob/main/both_tally_daybook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxDC9fLDZIjm"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR0J6hvdZQVT",
        "outputId": "165ff31a-d51c-4f34-87da-3dd96e1bc0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WoW6xYOdZkaD"
      },
      "outputs": [],
      "source": [
        "# prompt: list of files in the path in python\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "# Function to recursively extract text and sub-elements from a node\n",
        "def extract_element_data(element):\n",
        "    element_data = {}\n",
        "    # If the element has no children, return its text\n",
        "    if len(element) == 0:\n",
        "        return element.text\n",
        "\n",
        "    # Otherwise, go deeper into the element's children\n",
        "    for child in element:\n",
        "        # Recursively extract data for each child element\n",
        "        child_data = extract_element_data(child)\n",
        "        element_data[child.tag] = child_data\n",
        "    return element_data\n",
        "\n",
        "# Function to flatten nested dictionaries (e.g., 'amount': {'P': {'T': 100}})\n",
        "def flatten_dict(d, parent_key='', sep='.'):\n",
        "    items = []\n",
        "    for k, v in d.items():\n",
        "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "        if isinstance(v, dict):\n",
        "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
        "        else:\n",
        "            items.append((new_key, v))\n",
        "    return dict(items)\n",
        "\n",
        "# Function to recursively search for all 'voucher' elements and extract their data\n",
        "def find_all_vouchers(element, voucher_tag=\"VOUCHER\"):\n",
        "    vouchers = []\n",
        "\n",
        "    # If the current element is a 'voucher', collect its data\n",
        "    if element.tag == voucher_tag:\n",
        "        voucher_dict = {}\n",
        "        # Collect data for all child elements within the voucher\n",
        "        for sub_child in element:\n",
        "            extracted_data = extract_element_data(sub_child)\n",
        "            voucher_dict[sub_child.tag] = extracted_data\n",
        "\n",
        "        # Flatten the voucher dictionary to handle nested elements\n",
        "        voucher_dict_flattened = flatten_dict(voucher_dict)\n",
        "        vouchers.append(voucher_dict_flattened)\n",
        "\n",
        "    # Recursively search in all children of the current element\n",
        "    for child in element:\n",
        "        vouchers.extend(find_all_vouchers(child, voucher_tag))\n",
        "\n",
        "    return vouchers\n",
        "\n",
        "# Function to convert the XML to a DataFrame by extracting all vouchers\n",
        "def xml_to_dataframe_vouchers(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Find all 'voucher' elements in the XML\n",
        "    voucher_list = find_all_vouchers(root)\n",
        "\n",
        "    # Create a DataFrame from the list of voucher dictionaries\n",
        "    df = pd.DataFrame(voucher_list)\n",
        "    return df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bank_match_soe = pd.read_excel(\"/content/drive/My Drive/2024_25/overview_account.xlsx\",sheet_name='SOE 2024-25')\n",
        "df_bank_match_overview_soe = df_bank_match_soe.groupby('comment').agg({'Debit':'sum','Credit':'sum'}).reset_index().rename(columns={'comment':'party_name'})\n",
        "\n",
        "df_bank_match_me = pd.read_excel(\"/content/drive/My Drive/2024_25/overview_account.xlsx\",sheet_name='ME 2024-25')\n",
        "df_bank_match_overview_me = df_bank_match_me.groupby('comment').agg({'Debit':'sum','Credit':'sum'}).reset_index().rename(columns={'comment':'party_name'})"
      ],
      "metadata": {
        "id": "cgmJWFGXQc4v"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "3AiRkkfwrgPs"
      },
      "outputs": [],
      "source": [
        "files_soe = os.listdir('/content/drive/My Drive/2024_25/SOE/')\n",
        "files_me = os.listdir('/content/drive/My Drive/2024_25/ME/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "req_cols = ['DATE','GUID','VOUCHERTYPENAME','PARTYLEDGERNAME','PARTYGSTIN','CLASSNAME','PARTYNAME','CONSIGNEEGSTIN','PERSISTEDVIEW','ALLINVENTORYENTRIES.LIST.STOCKITEMNAME','ALLINVENTORYENTRIES.LIST.RATE','ALLINVENTORYENTRIES.LIST.AMOUNT','LEDGERENTRIES.LIST.VATEXPAMOUNT','LEDGERENTRIES.LIST.AMOUNT','ALLINVENTORYENTRIES.LIST.ACTUALQTY','ALLINVENTORYENTRIES.LIST.BILLEDQTY','ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.AMOUNT','ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.ACTUALQTY','ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.BILLEDQTY','ALLINVENTORYENTRIES.LIST.ACCOUNTINGALLOCATIONS.LIST.LEDGERNAME','ALLINVENTORYENTRIES.LIST.ACCOUNTINGALLOCATIONS.LIST.AMOUNT','LEDGERENTRIES.LIST.LEDGERNAME','LEDGERENTRIES.LIST.AMOUNT','LEDGERENTRIES.LIST.VATEXPAMOUNT','INVOICEORDERLIST.LIST.BASICORDERDATE','INVOICEORDERLIST.LIST.BASICPURCHASEORDERNO','REFERENCEDATE','REFERENCE','CONSIGNEEPINNUMBER','ALLINVENTORYENTRIES.LIST.ACCOUNTINGALLOCATIONS.LIST.GSTOVRDNNATURE','ALLINVENTORYENTRIES.LIST.ACCOUNTINGALLOCATIONS.LIST.RATEDETAILS.LIST.GSTRATEDUTYHEAD','ALLLEDGERENTRIES.LIST.OLDAUDITENTRYIDS.LIST.OLDAUDITENTRYIDS','ALLLEDGERENTRIES.LIST.LEDGERNAME','ALLLEDGERENTRIES.LIST.AMOUNT','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.DATE','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.INSTRUMENTDATE','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.NAME','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.TRANSACTIONTYPE','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.PAYMENTFAVOURING','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.CHEQUECROSSCOMMENT','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.UNIQUEREFERENCENUMBER','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.STATUS','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.PAYMENTMODE','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.BANKPARTYNAME','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.AMOUNT','NARRATION']\n",
        "df_raw_collect_soe = pd.DataFrame()\n",
        "for xt in files_soe:\n",
        "  path_ct = '/content/drive/My Drive/2024_25/SOE/'\n",
        "  xml_file = path_ct+xt\n",
        "  df_raw_f = xml_to_dataframe_vouchers(xml_file)[req_cols].reset_index(drop=True)\n",
        "  df_raw_f_ref = pd.DataFrame(df_raw_f)\n",
        "  df_raw_collect_soe = pd.concat([df_raw_collect_soe, df_raw_f_ref]).reset_index(drop=True)\n",
        "\n",
        "df_raw_soe = df_raw_collect_soe.drop_duplicates(subset='GUID', keep='first').reset_index(drop=True)\n",
        "df_raw_soe['date_column'] = pd.to_datetime(df_raw_soe['DATE'], format='%Y%m%d')\n",
        "df_raw_soe = df_raw_soe.sort_values('date_column')\n",
        "\n",
        "df_raw_collect_me = pd.DataFrame()\n",
        "for xt in files_me:\n",
        "  path_ct = '/content/drive/My Drive/2024_25/ME/'\n",
        "  xml_file = path_ct+xt\n",
        "  df_raw_f = xml_to_dataframe_vouchers(xml_file)[req_cols].reset_index(drop=True)\n",
        "  df_raw_f_ref = pd.DataFrame(df_raw_f)\n",
        "  df_raw_collect_me = pd.concat([df_raw_collect_me, df_raw_f_ref]).reset_index(drop=True)\n",
        "\n",
        "df_raw_me = df_raw_collect_me.drop_duplicates(subset='GUID', keep='first').reset_index(drop=True)\n",
        "df_raw_me['date_column'] = pd.to_datetime(df_raw_me['DATE'], format='%Y%m%d')\n",
        "df_raw_me = df_raw_me.sort_values('date_column')"
      ],
      "metadata": {
        "id": "K5L6GoEDvbmg"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_req_fields(df):\n",
        "  df['party_name'] = df[['PARTYNAME', 'ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.PAYMENTFAVOURING', 'ALLLEDGERENTRIES.LIST.LEDGERNAME']].bfill(axis=1).iloc[:, 0]\n",
        "  df['tax_out_1'] = df[['LEDGERENTRIES.LIST.AMOUNT']].bfill(axis=1).iloc[:, 0]\n",
        "  df['tax_out_2'] = df[['LEDGERENTRIES.LIST.VATEXPAMOUNT']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "  # df[''] = df[''].astype(float)\n",
        "  df['ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.AMOUNT'] = df['ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.AMOUNT'].astype(float)\n",
        "  df['tax_out_1'] = df['tax_out_1'].astype(float)\n",
        "  df['tax_out_2'] = df['tax_out_2'].astype(float)\n",
        "\n",
        "  df['amount_coalesce'] = df[['ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.AMOUNT', 'ALLLEDGERENTRIES.LIST.AMOUNT']].bfill(axis=1).iloc[:, 0]\n",
        "  df['amount_coalesce'] = df['amount_coalesce'].astype(float)\n",
        "  df['tax_coalesce'] = df[['tax_out_1', 'tax_out_2']].sum(axis=1)\n",
        "  df['total_coalesce'] = df[['tax_coalesce', 'amount_coalesce']].sum(axis=1)\n",
        "\n",
        "  df = df[['party_name','total_coalesce','amount_coalesce','tax_coalesce','tax_out_1','tax_out_2']+req_cols]\n",
        "  return df"
      ],
      "metadata": {
        "id": "XNtRcjgUAF05"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_me = add_req_fields(df_raw_me)\n",
        "df_soe = add_req_fields(df_raw_soe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SrhORyvhe1v",
        "outputId": "d7d7a5a1-cf78-4de6-bbda-b99fac7b857e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-bc721fa37c88>:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['amount_coalesce'] = df[['ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.AMOUNT', 'ALLLEDGERENTRIES.LIST.AMOUNT']].bfill(axis=1).iloc[:, 0]\n",
            "<ipython-input-45-bc721fa37c88>:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['amount_coalesce'] = df[['ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.AMOUNT', 'ALLLEDGERENTRIES.LIST.AMOUNT']].bfill(axis=1).iloc[:, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_soe['total_coalesce'] = df_soe['total_coalesce'].astype('float')\n",
        "df_summary_all_soe = pd.pivot_table(df_soe, values='total_coalesce', index='party_name', columns='VOUCHERTYPENAME', aggfunc='sum').reset_index()\n",
        "df_summary_all_soe['balance'] = 0\n",
        "df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='TIRUMALA MULTI TECHNOLOGIES'].index,'balance'] = 467646\n",
        "df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='SAVITA AUTO INDUSTRIES (N)'].index,'balance'] = 195853\n",
        "df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='PATIL-N-PATIL ENGINEERING\t'].index,'balance'] = 55660\n",
        "df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='NANDAMURI TECHNOS'].index,'balance'] = 35255\n",
        "df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='V.S.AUTO TECH PRIVATE LIMITED'].index,'balance'] = 4699956\n",
        "df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='A.B.ENGINEERING WORKS'].index,'balance'] = 11598\n",
        "\n",
        "df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='AKAR INDUSTRY'].index,'balance'] = 317899\n",
        "\n",
        "df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='SURYA AUTO INDUSTRIES'].index,'balance'] = 23165\n",
        "\n",
        "\n",
        "df_summary_all_soe = df_summary_all_soe.fillna(0)\n",
        "df_summary_all_soe['total_due']=df_summary_all_soe[['Contra', 'Credit Note', 'DELIVERY CHALLAN', 'Debit Note',\n",
        "       'Journal', 'Payment', 'Purchase', 'Receipt', 'SALES GST', 'balance']].sum(axis=1)\n",
        "\n",
        "df_me['total_coalesce'] = df_me['total_coalesce'].astype('float')\n",
        "df_summary_all_me = pd.pivot_table(df_me, values='total_coalesce', index='party_name', columns='VOUCHERTYPENAME', aggfunc='sum').reset_index()\n",
        "df_summary_all_me['balance'] = 0\n",
        "df_summary_all_me = df_summary_all_me.fillna(0)\n",
        "df_summary_all_me['total_due']=df_summary_all_me[[ 'Contra','Delivery Note','Debit Note','Sales Gst', 'Journal', 'Payment', 'Purchase', 'Receipt','Sales Gst','balance']].sum(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB4ofqqrIF3K",
        "outputId": "734e5534-0cb9-4a8a-8bbd-dcbdc5025fc2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-c45c9a62cf25>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_soe['total_coalesce'] = df_soe['total_coalesce'].astype('float')\n",
            "<ipython-input-47-c45c9a62cf25>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_me['total_coalesce'] = df_me['total_coalesce'].astype('float')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "terms = ['SHREE SAI ENGINEERING', 'XYZ COMPANY'] # Function to match and replace terms def match_and_replace(transaction): for term in terms: if term.replace(\" \", \"\").lower() in transaction.replace(\" \", \"\").lower(): return term return transaction # Or return a default value if no match is found # Apply function to the column df['renamed_column'] = df['transaction_column'"
      ],
      "metadata": {
        "id": "_dLjrfODnsqa"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_bank_match\n",
        "df_summary_all_bank_soe = pd.merge(df_summary_all_soe,df_bank_match_overview_soe,on=['party_name'],how='outer')\n",
        "df_summary_all_bank_soe = df_summary_all_bank_soe.sort_values(by='SALES GST', key=lambda x: x.isna()).reset_index(drop=True).sort_values(by='SALES GST', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# df_bank_match\n",
        "df_summary_all_bank_me = pd.merge(df_summary_all_me,df_bank_match_overview_me,on=['party_name'],how='outer')\n",
        "df_summary_all_bank_me = df_summary_all_bank_me.sort_values(by='Sales Gst', key=lambda x: x.isna()).reset_index(drop=True).sort_values(by='Sales Gst', ascending=False).reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "wHV_d94IRwaE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_summary_all_bank_me.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA1xladDj7p7",
        "outputId": "faa60840-986d-48a6-bc66-be25deda828a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['party_name', 'Contra', 'Debit Note', 'Delivery Note', 'Journal',\n",
              "       'Payment', 'Purchase', 'Receipt', 'Sales Gst', 'balance', 'total_due',\n",
              "       'Debit', 'Credit'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "columns_to_round_soe = ['Contra', 'Credit Note', 'DELIVERY CHALLAN', 'Debit Note','Journal', 'Payment', 'Purchase', 'Receipt', 'SALES GST', 'balance','total_due', 'Debit', 'Credit']\n",
        "df_summary_all_bank_soe[columns_to_round_soe] = df_summary_all_bank_soe[columns_to_round_soe].apply(np.ceil)\n",
        "\n",
        "columns_to_round_me = ['Contra', 'Debit Note', 'Delivery Note', 'Journal','Payment', 'Purchase', 'Receipt', 'Sales Gst', 'balance', 'total_due','Debit', 'Credit']\n",
        "df_summary_all_bank_me[columns_to_round_me] = df_summary_all_bank_me[columns_to_round_me].apply(np.ceil)"
      ],
      "metadata": {
        "id": "hPkVY1833bD1"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_summary_all_bank_soe.to_excel(\"/content/drive/My Drive/2024_25/daybook.xlsx\",sheet_name='SOE_overview')\n",
        "with pd.ExcelWriter(\"/content/drive/My Drive/2024_25/daybook.xlsx\",mode='a') as writer:\n",
        "  df_soe.to_excel(writer,sheet_name='SOE_raw_xml')"
      ],
      "metadata": {
        "id": "j0cQdNC9b4SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with pd.ExcelWriter(\"/content/drive/My Drive/2024_25/daybook.xlsx\",mode='a') as writer:\n",
        "  df_summary_all_bank_me.to_excel(writer,sheet_name='ME_overview')\n",
        "with pd.ExcelWriter(\"/content/drive/My Drive/2024_25/daybook.xlsx\",mode='a') as writer:\n",
        "  df_me.to_excel(writer,sheet_name='ME_raw_xml')\n",
        "\n",
        "# for xrow in df['VOUCHERTYPENAME'].unique().tolist():\n",
        "#   with pd.ExcelWriter(\"/content/drive/My Drive/2024_25/SOE_daybook.xlsx\",mode='a') as writer:\n",
        "#     df[df['VOUCHERTYPENAME']==xrow].reset_index(drop=True).to_excel(writer,sheet_name=xrow)\n"
      ],
      "metadata": {
        "id": "z2pbRc4CEuV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from datetime import datetime\n",
        "# path = '/content/drive/My Drive/2024_25'  # Replace with your desired path\n",
        "# files = os.listdir(path)\n",
        "# old_file_path  = '/content/drive/My Drive/2024_25/SOEDayBook.xlsx'\n",
        "# today_date = datetime.today().strftime('%Y-%m-%d')\n",
        "# if 'SOEDayBook.xlsx'  in files:\n",
        "#     # Create the new file name by appending today's date\n",
        "#   file_name, file_extension = os.path.splitext(old_file_path)\n",
        "#   new_file_path = f\"{file_name}_{today_date}{file_extension}\"\n",
        "\n",
        "#   # Rename the file\n",
        "#   os.rename(old_file_path, new_file_path)\n",
        "#   if not os.path.exists(old_file_path) and os.path.exists(new_file_path):\n",
        "#       print(f\"File renamed and saved as: {new_file_path}\")\n",
        "#       df.to_excel(\"/content/drive/My Drive/2024_25/SOE_daybook.xlsx\",sheet_name='master_sheet')\n",
        "\n",
        "#       for xrow in df['VOUCHERTYPENAME'].unique().tolist():\n",
        "#         with pd.ExcelWriter(\"/content/drive/My Drive/2024_25/SOE_daybook.xlsx\",mode='a') as writer:\n",
        "#           df[df['VOUCHERTYPENAME']==xrow].reset_index(drop=True).to_excel(writer,sheet_name=xrow)\n",
        "#   else:\n",
        "#       print(f\"Error renaming file: {old_file_path}\")"
      ],
      "metadata": {
        "id": "SsnUPM2lblBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT4KttNMv0y8"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# df['DATE'] = pd.to_datetime(df['DATE'])\n",
        "\n",
        "# df_sales = df[df['VOUCHERTYPENAME']=='SALES GST'].reset_index(drop=True)\n",
        "# # Calculate new dates\n",
        "# df_sales['DATE_plus_45'] = df_sales['DATE'] + pd.DateOffset(days=45)\n",
        "# df_sales['DATE_plus_60'] = df_sales['DATE'] + pd.DateOffset(days=60)\n",
        "# df_sales['DATE_plus_90'] = df_sales['DATE'] + pd.DateOffset(days=90)\n",
        "# df_sales['Week_Number'] = df_sales['DATE_plus_45'].dt.isocalendar().week\n",
        "# df_sales['ALLINVENTORYENTRIES.LIST.AMOUNT'] = df_sales['ALLINVENTORYENTRIES.LIST.AMOUNT'].astype(float)\n",
        "# df_sales = df_sales.rename(columns={'ALLINVENTORYENTRIES.LIST.AMOUNT': 'sales_amount'})\n",
        "# df_sales_g = df_sales.groupby(['PARTYLEDGERNAME','Week_Number'])['sales_amount'].sum().reset_index()\n",
        "\n",
        "# # Add a column for the payment due date (45 days after the sale date)\n",
        "# df_sales['due_date'] = df_sales['DATE'] + pd.Timedelta(days=45)\n",
        "\n",
        "# # Filter the DataFrame to include only pending payments (due date is in the future)\n",
        "# pending_payments = df_sales[df_sales['due_date'] > pd.Timestamp.now()]\n",
        "\n",
        "# # Group by customer name and week of the year, and sum the amounts\n",
        "# pending_payments_per_week = pending_payments.groupby(['PARTYLEDGERNAME'])['sales_amount'].sum().reset_index()\n",
        "\n",
        "# pending_payments_per_week.columns = ['PARTYLEDGERNAME', 'due_amount_'+str(pd.Timestamp.now().date())]\n",
        "# outstanding_payments_g = df_sales.groupby(['PARTYLEDGERNAME'])['sales_amount'].sum().reset_index()\n",
        "\n",
        "# outstanding_payments_g.columns = ['PARTYLEDGERNAME', 'outstanding_amount']\n",
        "# df_receipt = df[df['VOUCHERTYPENAME']=='Receipt'].reset_index(drop=True)\n",
        "# df_receipt['ALLLEDGERENTRIES.LIST.AMOUNT'] = df_receipt['ALLLEDGERENTRIES.LIST.AMOUNT'].astype(float)\n",
        "# df_receipt = df_receipt.rename(columns={'ALLLEDGERENTRIES.LIST.AMOUNT': 'receipt_amount'})\n",
        "# df_receipt_g = df_receipt.groupby(['PARTYLEDGERNAME'])['receipt_amount'].sum().reset_index()\n",
        "# df_due_45_days = pd.merge(df_receipt_g,outstanding_payments_g,on=['PARTYLEDGERNAME'],how='right')\n",
        "# df_due_45_days = pd.merge(df_due_45_days,pending_payments_per_week,on=['PARTYLEDGERNAME'],how='left')\n",
        "# df_due_45_days['closing_balance_on_31_march'] = ''\n",
        "# with pd.ExcelWriter(\"/content/drive/My Drive/2024_25/SOE_daybook.xlsx\",mode='a') as writer:\n",
        "#   df_due_45_days.to_excel(writer,sheet_name='Due_45_days')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gywaIhBc-QHP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}