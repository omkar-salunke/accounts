{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkar-salunke/accounts/blob/main/both_tally_daybook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR0J6hvdZQVT",
        "outputId": "769e41dd-61a0-42aa-d0f8-23aed3df8c47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "WoW6xYOdZkaD"
      },
      "outputs": [],
      "source": [
        "# prompt: list of files in the path in python\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "def extract_element_data(element):\n",
        "    element_data = {}\n",
        "    # If the element has no children, return its text\n",
        "    if len(element) == 0:\n",
        "        return element.text\n",
        "\n",
        "    # Otherwise, go deeper into the element's children\n",
        "    for child in element:\n",
        "        # Recursively extract data for each child element\n",
        "        child_data = extract_element_data(child)\n",
        "        element_data[child.tag] = child_data\n",
        "    return element_data\n",
        "\n",
        "# Function to flatten nested dictionaries (e.g., 'amount': {'P': {'T': 100}})\n",
        "def flatten_dict(d, parent_key='', sep='.'):\n",
        "    items = []\n",
        "    for k, v in d.items():\n",
        "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "        if isinstance(v, dict):\n",
        "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
        "        else:\n",
        "            items.append((new_key, v))\n",
        "    return dict(items)\n",
        "\n",
        "# Function to recursively search for all 'voucher' elements and extract their data\n",
        "def find_all_vouchers(element, voucher_tag=\"VOUCHER\"):\n",
        "    vouchers = []\n",
        "\n",
        "    # If the current element is a 'voucher', collect its data\n",
        "    if element.tag == voucher_tag:\n",
        "        voucher_dict = {}\n",
        "        # Collect data for all child elements within the voucher\n",
        "        for sub_child in element:\n",
        "            extracted_data = extract_element_data(sub_child)\n",
        "            voucher_dict[sub_child.tag] = extracted_data\n",
        "\n",
        "        # Flatten the voucher dictionary to handle nested elements\n",
        "        voucher_dict_flattened = flatten_dict(voucher_dict)\n",
        "        vouchers.append(voucher_dict_flattened)\n",
        "\n",
        "    # Recursively search in all children of the current element\n",
        "    for child in element:\n",
        "        vouchers.extend(find_all_vouchers(child, voucher_tag))\n",
        "\n",
        "    return vouchers\n",
        "\n",
        "# Function to convert the XML to a DataFrame by extracting all vouchers\n",
        "def xml_to_dataframe_vouchers(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Find all 'voucher' elements in the XML\n",
        "    voucher_list = find_all_vouchers(root)\n",
        "\n",
        "    # Create a DataFrame from the list of voucher dictionaries\n",
        "    df = pd.DataFrame(voucher_list)\n",
        "    return df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_bank_match_soe = pd.read_excel(\"/content/drive/My Drive/2024_25/overview_account.xlsx\",sheet_name='SOE 2024-25')\n",
        "# df_bank_match_overview_soe = df_bank_match_soe.groupby('comment').agg({'Debit':'sum','Credit':'sum'}).reset_index().rename(columns={'comment':'party_name'})\n",
        "\n",
        "# df_bank_match_me = pd.read_excel(\"/content/drive/My Drive/2024_25/overview_account.xlsx\",sheet_name='ME 2024-25')\n",
        "# df_bank_match_overview_me = df_bank_match_me.groupby('comment').agg({'Debit':'sum','Credit':'sum'}).reset_index().rename(columns={'comment':'party_name'})"
      ],
      "metadata": {
        "id": "cgmJWFGXQc4v"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "3AiRkkfwrgPs"
      },
      "outputs": [],
      "source": [
        "soe_list = '/content/drive/MyDrive/tally_export/SOE/'\n",
        "me_list = '/content/drive/MyDrive/tally_export/ME/'\n",
        "files_soe = os.listdir('/content/drive/MyDrive/tally_export/SOE/')\n",
        "files_me = os.listdir('/content/drive/MyDrive/tally_export/ME/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# xml_to_dataframe_vouchers('/content/drive/MyDrive/tally_export/ME/DayBook.xml')"
      ],
      "metadata": {
        "id": "q5Kj5-od-VdO"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UQuFxz3C6elr"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "req_cols = ['VOUCHERNUMBER','DATE','GUID','VOUCHERTYPENAME','PARTYLEDGERNAME','PARTYGSTIN','CLASSNAME','PARTYNAME','CONSIGNEEGSTIN','PERSISTEDVIEW','ALLINVENTORYENTRIES.LIST.STOCKITEMNAME','ALLINVENTORYENTRIES.LIST.RATE','ALLINVENTORYENTRIES.LIST.AMOUNT','LEDGERENTRIES.LIST.VATEXPAMOUNT','LEDGERENTRIES.LIST.AMOUNT','ALLINVENTORYENTRIES.LIST.ACTUALQTY','ALLINVENTORYENTRIES.LIST.BILLEDQTY','ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.AMOUNT','ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.ACTUALQTY','ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.BILLEDQTY','ALLINVENTORYENTRIES.LIST.ACCOUNTINGALLOCATIONS.LIST.LEDGERNAME','ALLINVENTORYENTRIES.LIST.ACCOUNTINGALLOCATIONS.LIST.AMOUNT','LEDGERENTRIES.LIST.LEDGERNAME','LEDGERENTRIES.LIST.AMOUNT','LEDGERENTRIES.LIST.VATEXPAMOUNT','INVOICEORDERLIST.LIST.BASICORDERDATE','INVOICEORDERLIST.LIST.BASICPURCHASEORDERNO','REFERENCEDATE','REFERENCE','CONSIGNEEPINNUMBER','ALLINVENTORYENTRIES.LIST.ACCOUNTINGALLOCATIONS.LIST.GSTOVRDNNATURE','ALLINVENTORYENTRIES.LIST.ACCOUNTINGALLOCATIONS.LIST.RATEDETAILS.LIST.GSTRATEDUTYHEAD','ALLLEDGERENTRIES.LIST.OLDAUDITENTRYIDS.LIST.OLDAUDITENTRYIDS','ALLLEDGERENTRIES.LIST.LEDGERNAME','ALLLEDGERENTRIES.LIST.AMOUNT','NARRATION']\n",
        "df_raw_collect_soe = pd.DataFrame()\n",
        "for xt in files_soe:\n",
        "  path_ct = soe_list\n",
        "  xml_file = path_ct+xt\n",
        "  df_raw_f = xml_to_dataframe_vouchers(xml_file)\n",
        "  df_raw_f_ref = pd.DataFrame(df_raw_f)[req_cols]\n",
        "  print(df_raw_f_ref.loc[0,'DATE'],df_raw_f_ref.loc[len(df_raw_f_ref)-1,'DATE'])\n",
        "  df_raw_collect_soe = pd.concat([df_raw_collect_soe, df_raw_f_ref]).reset_index(drop=True)\n",
        "df_raw_collect_soe\n",
        "\n",
        "df_raw_soe = df_raw_collect_soe.drop_duplicates(subset='GUID', keep='first').reset_index(drop=True)\n",
        "df_raw_soe['date_column'] = pd.to_datetime(df_raw_soe['DATE'], format='%Y%m%d')\n",
        "df_raw_soe = df_raw_soe.sort_values('date_column')\n",
        "df_raw_soe['date_column_month'] = df_raw_soe['date_column'].dt.month_name()\n",
        "df_raw_soe['act_qty'] = df_raw_soe['ALLINVENTORYENTRIES.LIST.ACTUALQTY'].str.extract(r'([\\d.]+)').astype(float)\n",
        "df_raw_soe_sales = df_raw_soe[df_raw_soe['VOUCHERTYPENAME'].isin(['Sales Gst', 'SALES GST'])]\n",
        "df_raw_soe_sales_sch = df_raw_soe_sales.groupby(['date_column_month','PARTYLEDGERNAME','ALLINVENTORYENTRIES.LIST.STOCKITEMNAME'])['act_qty'].sum()\n",
        "\n",
        "df_schedule_merge_soe = pd.DataFrame(df_raw_soe_sales_sch).pivot_table(index=['PARTYLEDGERNAME','ALLINVENTORYENTRIES.LIST.STOCKITEMNAME'],columns='date_column_month',values='act_qty',aggfunc='sum').reset_index()\n",
        "df_schedule_merge_soe['FROM']=\"SOE\"\n",
        "\n",
        "# df_schedule = pd.read_excel(\"/content/drive/MyDrive/tally_export/schedule.xlsx\",sheet_name = 'SOE')\n",
        "# df_schedule_merge_soe = pd.merge(df_schedule,df_raw_soe_sales_schedule,on=['PARTYLEDGERNAME','ALLINVENTORYENTRIES.LIST.STOCKITEMNAME'],how='right')\n",
        "# df_schedule_merge.to_excel(,sheet_name = 'SOE',index=False)\n",
        "df_schedule_merge_soe\n",
        "\n",
        "# df_raw_soe_sales.sort_values('date_column')\n",
        "\n"
      ],
      "metadata": {
        "id": "nT_fKGFe8bcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c00d6d3-f0b7-44e5-8e28-917abcc522e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20250502 20250519\n",
            "20250502 20250519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zoho_col_list = ['Invoice Number',\n",
        "'Estimate Number',\n",
        "'Invoice Date',\n",
        "'Invoice Status',\n",
        "'Customer Name',\n",
        "'GST Treatment',\n",
        "'TCS Tax Name',\n",
        "'TCS Percentage',\n",
        "'TCS Amount',\n",
        "'Nature Of Collection',\n",
        "'TCS Payable Account',\n",
        "'TCS Receivable Account',\n",
        "'GST Identification Number (GSTIN)',\n",
        "'TDS Name',\n",
        "'TDS Percentage',\n",
        "'TDS Section Code',\n",
        "'TDS Amount',\n",
        "'Place of Supply',\n",
        "'PurchaseOrder',\n",
        "'Expense Reference ID',\n",
        "'Payment Terms',\n",
        "'Payment Terms Label',\n",
        "'Due Date',\n",
        "'Expected Payment Date',\n",
        "'Sales person',\n",
        "'Shipping Charge Tax Name',\n",
        "'Shipping Charge Tax Type',\n",
        "'Shipping Charge Tax %',\n",
        "'Shipping Charge',\n",
        "'Shipping Charge Tax Exemption Code',\n",
        "'Shipping Charge SAC Code',\n",
        "'Currency Code',\n",
        "'Exchange Rate',\n",
        "'Account',\n",
        "'Item Name',\n",
        "'SKU',\n",
        "'Item Desc',\n",
        "'Item Type',\n",
        "'HSN/SAC',\n",
        "'Quantity',\n",
        "'Usage unit',\n",
        "'Item Price',\n",
        "'Item Tax Exemption Reason',\n",
        "'Is Inclusive Tax',\n",
        "'Item Tax',\n",
        "'Item Tax Type',\n",
        "'Item Tax %',\n",
        "'Reverse Charge Tax Name',\n",
        "'Reverse Charge Tax Rate',\n",
        "'Reverse Charge Tax Type',\n",
        "'Project Name',\n",
        "'Supply Type',\n",
        "'Discount Type',\n",
        "'Is Discount Before Tax',\n",
        "'Entity Discount Percent',\n",
        "'Entity Discount Amount',\n",
        "'Discount',\n",
        "'Discount Amount',\n",
        "'Adjustment',\n",
        "'Adjustment Description',\n",
        "'E-Commerce Operator Name',\n",
        "'E-Commerce Operator GSTIN',\n",
        "'PayPal',\n",
        "'Razorpay',\n",
        "'Partial Payments',\n",
        "'Template Name',\n",
        "'Notes',\n",
        "'Terms & Conditions',\n",
        "'Branch Name']"
      ],
      "metadata": {
        "id": "z-uh7VcpT_sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# req_cols = ['DATE','GUID','VOUCHERTYPENAME','PARTYLEDGERNAME','PARTYGSTIN','CLASSNAME','PARTYNAME','CONSIGNEEGSTIN','PERSISTEDVIEW','ALLINVENTORYENTRIES.LIST.STOCKITEMNAME','ALLINVENTORYENTRIES.LIST.RATE','ALLINVENTORYENTRIES.LIST.AMOUNT','LEDGERENTRIES.LIST.VATEXPAMOUNT','LEDGERENTRIES.LIST.AMOUNT','ALLINVENTORYENTRIES.LIST.ACTUALQTY','ALLINVENTORYENTRIES.LIST.BILLEDQTY','ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.AMOUNT','ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.ACTUALQTY','ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.BILLEDQTY','ALLINVENTORYENTRIES.LIST.ACCOUNTINGALLOCATIONS.LIST.LEDGERNAME','ALLINVENTORYENTRIES.LIST.ACCOUNTINGALLOCATIONS.LIST.AMOUNT','LEDGERENTRIES.LIST.LEDGERNAME','LEDGERENTRIES.LIST.AMOUNT','LEDGERENTRIES.LIST.VATEXPAMOUNT','INVOICEORDERLIST.LIST.BASICORDERDATE','INVOICEORDERLIST.LIST.BASICPURCHASEORDERNO','REFERENCEDATE','REFERENCE','CONSIGNEEPINNUMBER','ALLINVENTORYENTRIES.LIST.ACCOUNTINGALLOCATIONS.LIST.GSTOVRDNNATURE','ALLINVENTORYENTRIES.LIST.ACCOUNTINGALLOCATIONS.LIST.RATEDETAILS.LIST.GSTRATEDUTYHEAD','ALLLEDGERENTRIES.LIST.OLDAUDITENTRYIDS.LIST.OLDAUDITENTRYIDS','ALLLEDGERENTRIES.LIST.LEDGERNAME','ALLLEDGERENTRIES.LIST.AMOUNT','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.DATE','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.INSTRUMENTDATE','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.NAME','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.TRANSACTIONTYPE','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.PAYMENTFAVOURING','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.CHEQUECROSSCOMMENT','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.UNIQUEREFERENCENUMBER','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.STATUS','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.PAYMENTMODE','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.BANKPARTYNAME','ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.AMOUNT','NARRATION']\n",
        "df_raw_collect_soe = pd.DataFrame()\n",
        "for xt in files_me:\n",
        "  path_ct = me_list\n",
        "  xml_file = path_ct+xt\n",
        "  df_raw_f = xml_to_dataframe_vouchers(xml_file)\n",
        "  df_raw_f_ref = pd.DataFrame(df_raw_f)[req_cols]\n",
        "  df_raw_collect_soe = pd.concat([df_raw_collect_soe, df_raw_f_ref]).reset_index(drop=True)\n",
        "# df_raw_collect_soe\n",
        "df_raw_soe = df_raw_collect_soe.drop_duplicates(subset='GUID', keep='first').reset_index(drop=True)\n",
        "df_raw_soe['date_column'] = pd.to_datetime(df_raw_soe['DATE'], format='%Y%m%d')\n",
        "df_raw_soe = df_raw_soe.sort_values('date_column')\n",
        "df_raw_soe['date_column_month'] = df_raw_soe['date_column'].dt.month_name()\n",
        "df_raw_soe['act_qty'] = df_raw_soe['ALLINVENTORYENTRIES.LIST.ACTUALQTY'].str.extract(r'([\\d.]+)').astype(float)\n",
        "\n",
        "df_raw_me_sales = df_raw_soe[df_raw_soe['VOUCHERTYPENAME'].isin(['Sales Gst', 'SALES GST'])]\n",
        "df_raw_me_sales_sch = df_raw_me_sales.groupby(['date_column_month','PARTYLEDGERNAME','ALLINVENTORYENTRIES.LIST.STOCKITEMNAME'])['act_qty'].sum()\n",
        "\n",
        "df_schedule_merge_me = pd.DataFrame(df_raw_me_sales_sch).pivot_table(index=['PARTYLEDGERNAME','ALLINVENTORYENTRIES.LIST.STOCKITEMNAME'],columns='date_column_month',values='act_qty',aggfunc='sum').reset_index()\n",
        "df_schedule_merge_me['FROM']=\"ME\"\n",
        "\n",
        "# df_schedule = pd.read_excel(\"/content/drive/MyDrive/tally_export/schedule.xlsx\",sheet_name = 'ME')\n",
        "# df_raw_soe_sales_schedule\n",
        "# df_schedule_merge_me = pd.merge(df_schedule,df_raw_soe_sales_schedule,on=['PARTYLEDGERNAME','ALLINVENTORYENTRIES.LIST.STOCKITEMNAME'],how='right')\n",
        "\n",
        "# writer = pd.ExcelWriter(\"/content/drive/MyDrive/tally_export/schedule_overview.xlsx\", engine = 'openpyxl')\n",
        "# df_schedule_merge_soe.to_excel(writer, sheet_name = 'SOE')\n",
        "# df_schedule_merge_me.to_excel(writer, sheet_name = 'ME')\n",
        "# writer.close()\n",
        "df_raw_me_sales.sort_values('date_column')\n"
      ],
      "metadata": {
        "id": "PFZGdd4Ntqcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_schedule = pd.read_excel(\"/content/drive/MyDrive/tally_export/schedule_overview.xlsx\",sheet_name = 'Planned_Schedule')\n",
        "# df_raw_soe_sales_schedule\n",
        "df_schedule"
      ],
      "metadata": {
        "id": "NaqjBqt6tyST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concat = pd.concat([df_schedule_merge_me,df_schedule_merge_soe]).rename(columns={\"PARTYLEDGERNAME\":\"TO\",\"ALLINVENTORYENTRIES.LIST.STOCKITEMNAME\":\"part_tally_name\"})\n",
        "from datetime import date\n",
        "df_schedule_merge_relate = pd.merge(df_schedule,df_concat,on=['FROM','TO','part_tally_name'],how='right')\n",
        "df_schedule_merge_relate\n",
        "month = \"May\"\n",
        "df_schedule_merge_relate['balance_'+month+'_'+str(date.today())] = df_schedule_merge_relate['Schedule_'+month]-df_schedule_merge_relate[month]\n",
        "df_schedule_merge_relate = df_schedule_merge_relate[['FROM','TO','part_tally_name']+[month]+['Schedule_'+month]+['balance_'+month+'_'+str(date.today())]]\n",
        "df_schedule_merge_relate"
      ],
      "metadata": {
        "id": "36bOyVJPtQlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from openpyxl import load_workbook\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/tally_export/schedule_overview.xlsx\"\n",
        "\n",
        "# Load existing workbook\n",
        "wb = load_workbook(filename=file_path)\n",
        "\n",
        "# Define a function to clear and update a sheet\n",
        "def update_sheet(sheet_name, df):\n",
        "    if sheet_name in wb.sheetnames:\n",
        "        ws = wb[sheet_name]\n",
        "        # Clear existing cells (except formats)\n",
        "        for row in ws.iter_rows(min_row=1, max_row=ws.max_row, max_col=ws.max_column):\n",
        "            for cell in row:\n",
        "                cell.value = None\n",
        "    else:\n",
        "        ws = wb.create_sheet(title=sheet_name)\n",
        "\n",
        "    # Write new data\n",
        "    for r_idx, row in enumerate(dataframe_to_rows(df, index=False, header=True), 1):\n",
        "        for c_idx, value in enumerate(row, 1):\n",
        "            ws.cell(row=r_idx, column=c_idx, value=value)\n",
        "\n",
        "# Update only the target sheets\n",
        "update_sheet('SOE', df_schedule_merge_soe)\n",
        "update_sheet('ME', df_schedule_merge_me)\n",
        "update_sheet(month, df_schedule_merge_relate)\n",
        "\n",
        "# Save to a temp file then replace the original (for GDrive safety)\n",
        "temp_path = \"/content/temp_schedule_overview.xlsx\"\n",
        "wb.save(temp_path)\n",
        "\n",
        "import shutil\n",
        "shutil.copy(temp_path, file_path)\n"
      ],
      "metadata": {
        "id": "f6ziFawimfmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw_soe_sales['CLASSNAME'].unique().tolist()"
      ],
      "metadata": {
        "id": "g-l9IpFn1i1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw_soe_sales['LEDGERENTRIES.LIST.LEDGERNAME'].unique()"
      ],
      "metadata": {
        "id": "nGBOZRUP4Jkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw_soe_sales[~df_raw_soe_sales['CLASSNAME'].isin(['SALES 28%', 'SALES 18%', 'SALES 12%'])].to_csv('temp.csv')"
      ],
      "metadata": {
        "id": "izkanir60CMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw_soe_sales['date_column_zoho'] = pd.to_datetime(df_raw_soe_sales['DATE'], format='%Y%m%d')\n",
        "df_raw_soe_sales['date_column_zoho'] = df_raw_soe_sales['date_column_zoho'].dt.strftime('%Y-%m-%d')\n",
        "df_raw_soe_sales['GST Treatment']=\"business_gst\"\n",
        "df_raw_soe_sales[\"Place of Supply\"] = \"MH\"\n",
        "df_raw_soe_sales[\"Payment Terms\"] = 45\n",
        "df_raw_soe_sales[\"Account\"] = \"Sales\"\n",
        "df_raw_soe_sales[\"Item Type\"] = \"goods\"\n",
        "df_raw_soe_sales[\"HSN/SAC\"] = \"87081010\"\n",
        "df_raw_soe_sales[\"Supply Type\"] = \"Taxable\"\n",
        "\n",
        "df_raw_soe_sales['Invoice Status'] = \"open\"\n",
        "df_raw_soe_sales['Item Tax Type'] = \"Tax Group\"\n",
        "# try:\n",
        "df_raw_soe_sales['tax_perc1'] = df_raw_soe_sales['CLASSNAME'].str.extract(r'(\\d+)')\n",
        "df_raw_soe_sales['tax_perc2'] = df_raw_soe_sales['LEDGERENTRIES.LIST.LEDGERNAME'].str.extract(r'(\\d+)').fillna(0).astype(int)*2\n",
        "\n",
        "df_raw_soe_sales['tax_perc'] = df_raw_soe_sales['tax_perc1'].fillna(df_raw_soe_sales['tax_perc2']).astype(int)\n",
        "\n",
        "#\n",
        "df_raw_soe_sales['Item Tax'] = \"GST\"+df_raw_soe_sales['tax_perc'].astype(str)\n",
        "df_raw_soe_sales['Item Price']=df_raw_soe_sales['ALLINVENTORYENTRIES.LIST.RATE'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
        "\n",
        "df_raw_soe_sales_rename = df_raw_soe_sales.rename(columns = {\"VOUCHERNUMBER\":\"Invoice Number\",\"date_column_zoho\":\"Invoice Date\",\"PARTYGSTIN\":\"GST Identification Number (GSTIN)\",\"INVOICEORDERLIST.LIST.BASICPURCHASEORDERNO\":\"PurchaseOrder\",\n",
        "                                   \"tax_perc\":\"Item Tax %\",\"ALLINVENTORYENTRIES.LIST.STOCKITEMNAME\":\"Item Name\",\"act_qty\":\"Quantity\",\n",
        "                                   \"PARTYLEDGERNAME\":\"Customer Name\"})\n",
        "\n",
        "req_columns = []\n",
        "for xl in list(df_raw_soe_sales_rename.columns):\n",
        "  if xl in zoho_col_list:\n",
        "    req_columns.append(xl)\n",
        "\n",
        "df_raw_soe_sales_rename[req_columns].to_csv(\"/content/drive/MyDrive/tally_export/SOE_zoho_sales_invoice.csv\",index=False)"
      ],
      "metadata": {
        "id": "iAHfmJhPW0T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw_soe_sales[df_raw_soe_sales['tax_perc1'].isnull()]"
      ],
      "metadata": {
        "id": "MUTzGdNd-VGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw_soe_sales['tax_perc'].unique()"
      ],
      "metadata": {
        "id": "muqwsZmd4tyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw_soe_sales_rename[(df_raw_soe_sales_rename['Customer Name']=='AKAR INDUSTRY')&(df_raw_soe_sales_rename['Item Name']=='Tab Washer')].to_csv('temp.csv')"
      ],
      "metadata": {
        "id": "UvtUsw6Ry8Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def add_req_fields(df):\n",
        "#   df['party_name'] = df[['PARTYNAME', 'ALLLEDGERENTRIES.LIST.BANKALLOCATIONS.LIST.PAYMENTFAVOURING', 'ALLLEDGERENTRIES.LIST.LEDGERNAME']].bfill(axis=1).iloc[:, 0]\n",
        "#   df['tax_out_1'] = df[['LEDGERENTRIES.LIST.AMOUNT']].bfill(axis=1).iloc[:, 0]\n",
        "#   df['tax_out_2'] = df[['LEDGERENTRIES.LIST.VATEXPAMOUNT']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "#   # df[''] = df[''].astype(float)\n",
        "#   df['ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.AMOUNT'] = df['ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.AMOUNT'].astype(float)\n",
        "#   df['tax_out_1'] = df['tax_out_1'].astype(float)\n",
        "#   df['tax_out_2'] = df['tax_out_2'].astype(float)\n",
        "\n",
        "#   df['amount_coalesce'] = df[['ALLINVENTORYENTRIES.LIST.BATCHALLOCATIONS.LIST.AMOUNT', 'ALLLEDGERENTRIES.LIST.AMOUNT']].bfill(axis=1).iloc[:, 0]\n",
        "#   df['amount_coalesce'] = df['amount_coalesce'].astype(float)\n",
        "#   df['tax_coalesce'] = df[['tax_out_1', 'tax_out_2']].sum(axis=1)\n",
        "#   df['total_coalesce'] = df[['tax_coalesce', 'amount_coalesce']].sum(axis=1)\n",
        "\n",
        "#   df = df[['party_name','total_coalesce','amount_coalesce','tax_coalesce','tax_out_1','tax_out_2']+req_cols]\n",
        "#   return df"
      ],
      "metadata": {
        "id": "XNtRcjgUAF05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_me = add_req_fields(df_raw_me)\n",
        "# df_me['DATE'] = pd.to_datetime(df_me['DATE'])\n",
        "# df_me['month_of_day'] =df_me['DATE'].dt.month\n",
        "# df_me['quarter_of_day'] =df_me['DATE'].dt.quarter\n",
        "\n",
        "# df_soe = add_req_fields(df_raw_soe)\n",
        "# df_soe['DATE'] = pd.to_datetime(df_soe['DATE'])\n",
        "# df_soe['month_of_day'] =df_soe['DATE'].dt.month\n",
        "# df_soe['quarter_of_day'] =df_soe['DATE'].dt.quarter\n"
      ],
      "metadata": {
        "id": "2SrhORyvhe1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# df_soe['total_coalesce'] = df_soe['total_coalesce'].astype('float')\n",
        "# df_summary_all_soe = pd.pivot_table(df_soe, values='total_coalesce', index='party_name', columns='VOUCHERTYPENAME', aggfunc='sum').reset_index()\n",
        "# df_summary_all_soe['balance'] = 0\n",
        "# df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='TIRUMALA MULTI TECHNOLOGIES'].index,'balance'] = 467646\n",
        "# df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='SAVITA AUTO INDUSTRIES (N)'].index,'balance'] = 195853\n",
        "# df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='PATIL-N-PATIL ENGINEERING\t'].index,'balance'] = 55660\n",
        "# df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='NANDAMURI TECHNOS'].index,'balance'] = 35255\n",
        "# df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='V.S.AUTO TECH PRIVATE LIMITED'].index,'balance'] = 4699956\n",
        "# df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='A.B.ENGINEERING WORKS'].index,'balance'] = 11598\n",
        "\n",
        "# df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='AKAR INDUSTRY'].index,'balance'] = 317899\n",
        "\n",
        "# df_summary_all_soe.loc[df_summary_all_soe[df_summary_all_soe['party_name']=='SURYA AUTO INDUSTRIES'].index,'balance'] = 23165\n",
        "\n",
        "\n",
        "# df_summary_all_soe = df_summary_all_soe.fillna(0)\n",
        "# df_summary_all_soe['total_due']=df_summary_all_soe[['Contra', 'Credit Note', 'DELIVERY CHALLAN', 'Debit Note',\n",
        "#        'Journal', 'Payment', 'Purchase', 'Receipt', 'SALES GST', 'balance']].sum(axis=1)\n",
        "\n",
        "# df_me['total_coalesce'] = df_me['total_coalesce'].astype('float')\n",
        "# df_summary_all_me = pd.pivot_table(df_me, values='total_coalesce', index='party_name', columns='VOUCHERTYPENAME', aggfunc='sum').reset_index()\n",
        "# df_summary_all_me['balance'] = 0\n",
        "# df_summary_all_me = df_summary_all_me.fillna(0)\n",
        "# df_summary_all_me['total_due']=df_summary_all_me[[ 'Contra','Delivery Note','Debit Note','Sales Gst', 'Journal', 'Payment', 'Purchase', 'Receipt','Sales Gst','balance']].sum(axis=1)"
      ],
      "metadata": {
        "id": "qB4ofqqrIF3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# terms = ['SHREE SAI ENGINEERING', 'XYZ COMPANY'] # Function to match and replace terms def match_and_replace(transaction): for term in terms: if term.replace(\" \", \"\").lower() in transaction.replace(\" \", \"\").lower(): return term return transaction # Or return a default value if no match is found # Apply function to the column df['renamed_column'] = df['transaction_column'"
      ],
      "metadata": {
        "id": "_dLjrfODnsqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # df_bank_match\n",
        "# df_summary_all_bank_soe = pd.merge(df_summary_all_soe,df_bank_match_overview_soe,on=['party_name'],how='outer')\n",
        "# df_summary_all_bank_soe = df_summary_all_bank_soe.sort_values(by='SALES GST', key=lambda x: x.isna()).reset_index(drop=True).sort_values(by='SALES GST', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# # df_bank_match\n",
        "# df_summary_all_bank_me = pd.merge(df_summary_all_me,df_bank_match_overview_me,on=['party_name'],how='outer')\n",
        "# df_summary_all_bank_me = df_summary_all_bank_me.sort_values(by='Sales Gst', key=lambda x: x.isna()).reset_index(drop=True).sort_values(by='Sales Gst', ascending=False).reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "wHV_d94IRwaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# df_sales = df_soe[df_soe['VOUCHERTYPENAME']=='SALES GST'].reset_index(drop=True)\n",
        "# # df_sales = df_sales.rename(columns={'ALLINVENTORYENTRIES.LIST.AMOUNT': 'sales_amount'})\n",
        "# df_sales_g = df_sales.groupby(['PARTYLEDGERNAME'])['total_coalesce'].sum().reset_index().rename(columns={\"total_coalesce\":\"total_sales\",\"PARTYLEDGERNAME\":\"party_name\"})\n",
        "# date_45d = max(df_sales['DATE']) - pd.Timedelta(days=45)\n",
        "# due45 = df_sales[df_sales['DATE'] > date_45d]\n",
        "# due45_g = due45.groupby(['PARTYLEDGERNAME'])['total_coalesce'].sum().reset_index().rename(columns={\"total_coalesce\":\"Sale_45d\",\"PARTYLEDGERNAME\":\"party_name\"})\n",
        "\n",
        "# date_60d = max(df_sales['DATE']) - pd.Timedelta(days=60)\n",
        "# due60 = df_sales[df_sales['DATE'] > date_60d]\n",
        "# due60_g = due60.groupby(['PARTYLEDGERNAME'])['total_coalesce'].sum().reset_index().rename(columns={\"total_coalesce\":\"Sale_60d\",\"PARTYLEDGERNAME\":\"party_name\"})\n",
        "\n",
        "# date_90d = max(df_sales['DATE']) - pd.Timedelta(days=90)\n",
        "# due90 = df_sales[df_sales['DATE'] > date_90d]\n",
        "# due90_g = due90.groupby(['PARTYLEDGERNAME'])['total_coalesce'].sum().reset_index().rename(columns={\"total_coalesce\":\"Sale_90d\",\"PARTYLEDGERNAME\":\"party_name\"})\n",
        "\n",
        "# # df_summary_all_bank_soe_due = pd.merge(df_summary_all_bank_soe,df_sales_g,on=['party_name'],how='left')\n",
        "# df_summary_all_bank_soe_due = pd.merge(df_summary_all_bank_soe,due45_g,on=['party_name'],how='left')\n",
        "# df_summary_all_bank_soe_due = pd.merge(df_summary_all_bank_soe_due,due60_g,on=['party_name'],how='left')\n",
        "# df_summary_all_bank_soe_due = pd.merge(df_summary_all_bank_soe_due,due90_g,on=['party_name'],how='left')\n",
        "# df_summary_all_bank_soe_due = df_summary_all_bank_soe_due.fillna(0)\n",
        "# df_summary_all_bank_soe_due['true_credit'] = df_summary_all_bank_soe_due['Credit']-df_summary_all_bank_soe_due['balance']\n",
        "# # df_summary_all_bank_soe_due"
      ],
      "metadata": {
        "id": "cVvXx6dpooKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# df_sales = df_me[df_me['VOUCHERTYPENAME']=='Sales Gst'].reset_index(drop=True)\n",
        "# # df_sales = df_sales.rename(columns={'ALLINVENTORYENTRIES.LIST.AMOUNT': 'sales_amount'})\n",
        "# df_sales_g = df_sales.groupby(['PARTYLEDGERNAME'])['total_coalesce'].sum().reset_index().rename(columns={\"total_coalesce\":\"total_sales\",\"PARTYLEDGERNAME\":\"party_name\"})\n",
        "# date_45d = max(df_sales['DATE']) - pd.Timedelta(days=45)\n",
        "# due45 = df_sales[df_sales['DATE'] > date_45d]\n",
        "# due45_g = due45.groupby(['PARTYLEDGERNAME'])['total_coalesce'].sum().reset_index().rename(columns={\"total_coalesce\":\"Sale_45d\",\"PARTYLEDGERNAME\":\"party_name\"})\n",
        "\n",
        "# date_60d = max(df_sales['DATE']) - pd.Timedelta(days=60)\n",
        "# due60 = df_sales[df_sales['DATE'] > date_60d]\n",
        "# due60_g = due60.groupby(['PARTYLEDGERNAME'])['total_coalesce'].sum().reset_index().rename(columns={\"total_coalesce\":\"Sale_60d\",\"PARTYLEDGERNAME\":\"party_name\"})\n",
        "\n",
        "# date_90d = max(df_sales['DATE']) - pd.Timedelta(days=90)\n",
        "# due90 = df_sales[df_sales['DATE'] > date_90d]\n",
        "# due90_g = due90.groupby(['PARTYLEDGERNAME'])['total_coalesce'].sum().reset_index().rename(columns={\"total_coalesce\":\"Sale_90d\",\"PARTYLEDGERNAME\":\"party_name\"})\n",
        "\n",
        "# # df_summary_all_bank_me_due = pd.merge(df_summary_all_bank_me,df_sales_g,on=['party_name'],how='left')\n",
        "# df_summary_all_bank_me_due = pd.merge(df_summary_all_bank_me,due45_g,on=['party_name'],how='left')\n",
        "# df_summary_all_bank_me_due = pd.merge(df_summary_all_bank_me_due,due60_g,on=['party_name'],how='left')\n",
        "# df_summary_all_bank_me_due = pd.merge(df_summary_all_bank_me_due,due90_g,on=['party_name'],how='left')\n",
        "# df_summary_all_bank_me_due = df_summary_all_bank_me_due.fillna(0)\n",
        "# df_summary_all_bank_me_due['true_credit'] = df_summary_all_bank_me_due['Credit']-df_summary_all_bank_me_due['balance']\n",
        "# # df_summary_all_bank_me_due"
      ],
      "metadata": {
        "id": "vA1xladDj7p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# columns_to_round_soe = ['Contra', 'Credit Note', 'DELIVERY CHALLAN', 'Debit Note','Journal', 'Payment', 'Purchase', 'Receipt', 'SALES GST', 'balance','total_due', 'Debit', 'Credit','Sale_45d','Sale_60d','Sale_90d']\n",
        "# df_summary_all_bank_soe_due[columns_to_round_soe] = df_summary_all_bank_soe_due[columns_to_round_soe].apply(np.ceil)\n",
        "\n",
        "# columns_to_round_me = ['Contra', 'Debit Note', 'Delivery Note', 'Journal','Payment', 'Purchase', 'Receipt', 'Sales Gst', 'balance', 'total_due','Debit', 'Credit','Sale_45d','Sale_60d','Sale_90d']\n",
        "# df_summary_all_bank_me_due[columns_to_round_me] = df_summary_all_bank_me_due[columns_to_round_me].apply(np.ceil)"
      ],
      "metadata": {
        "id": "hPkVY1833bD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from openpyxl import load_workbook\n",
        "# from datetime import datetime\n",
        "\n",
        "# # Define file path and sheet name\n",
        "# file_path = \"/content/drive/My Drive/2024_25/daybook.xlsx\"\n",
        "# original_sheet_name = \"SOE_overview\"\n",
        "\n",
        "# # Get the current date to use in the renamed sheet name\n",
        "# date_str = datetime.now().strftime(\"%Y_%m_%d\")\n",
        "# renamed_sheet_name = f\"{original_sheet_name}_{date_str}\"\n",
        "\n",
        "# # Load the workbook and rename the sheet if it exists\n",
        "# workbook = load_workbook(file_path)\n",
        "\n",
        "# if original_sheet_name in workbook.sheetnames:\n",
        "#     # Rename the existing sheet\n",
        "#     sheet = workbook[original_sheet_name]\n",
        "#     sheet.title = renamed_sheet_name\n",
        "#     sheet.sheet_state = 'hidden'  # Hide the sheet\n",
        "\n",
        "# # Save the workbook after renaming and hiding the sheet\n",
        "# workbook.save(file_path)\n",
        "\n",
        "# # Write the new data to the original sheet name\n",
        "# with pd.ExcelWriter(file_path, mode='a', engine='openpyxl') as writer:\n",
        "#     df_summary_all_bank_soe_due.to_excel(writer, sheet_name=original_sheet_name, index=False)\n"
      ],
      "metadata": {
        "id": "Zzg1eHNKzh6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# original_sheet_name = \"SOE_raw_xml\"\n",
        "\n",
        "# # Get the current date to use in the renamed sheet name\n",
        "# date_str = datetime.now().strftime(\"%Y_%m_%d\")\n",
        "# renamed_sheet_name = f\"{original_sheet_name}_{date_str}\"\n",
        "\n",
        "# # Load the workbook and rename the sheet if it exists\n",
        "# workbook = load_workbook(file_path)\n",
        "\n",
        "# if original_sheet_name in workbook.sheetnames:\n",
        "#     # Rename the existing sheet\n",
        "#     sheet = workbook[original_sheet_name]\n",
        "#     sheet.title = renamed_sheet_name\n",
        "#     sheet.sheet_state = 'hidden'  # Hide the sheet\n",
        "\n",
        "# # Save the workbook after renaming and hiding the sheet\n",
        "# workbook.save(file_path)\n",
        "\n",
        "# # Write the new data to the original sheet name\n",
        "# with pd.ExcelWriter(file_path, mode='a', engine='openpyxl') as writer:\n",
        "#     df_soe.to_excel(writer, sheet_name=original_sheet_name, index=False)"
      ],
      "metadata": {
        "id": "w3R6wL5x0O62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# original_sheet_name = \"ME_overview\"\n",
        "\n",
        "# # Get the current date to use in the renamed sheet name\n",
        "# date_str = datetime.now().strftime(\"%Y_%m_%d\")\n",
        "# renamed_sheet_name = f\"{original_sheet_name}_{date_str}\"\n",
        "\n",
        "# # Load the workbook and rename the sheet if it exists\n",
        "# workbook = load_workbook(file_path)\n",
        "\n",
        "# if original_sheet_name in workbook.sheetnames:\n",
        "#     # Rename the existing sheet\n",
        "#     sheet = workbook[original_sheet_name]\n",
        "#     sheet.title = renamed_sheet_name\n",
        "#     sheet.sheet_state = 'hidden'  # Hide the sheet\n",
        "\n",
        "# # Save the workbook after renaming and hiding the sheet\n",
        "# workbook.save(file_path)\n",
        "\n",
        "# # Write the new data to the original sheet name\n",
        "# with pd.ExcelWriter(file_path, mode='a', engine='openpyxl') as writer:\n",
        "#     df_summary_all_bank_me_due.to_excel(writer, sheet_name=original_sheet_name, index=False)"
      ],
      "metadata": {
        "id": "cywYr9LO0Y76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# original_sheet_name = \"ME_raw_xml\"\n",
        "\n",
        "# # Get the current date to use in the renamed sheet name\n",
        "# date_str = datetime.now().strftime(\"%Y_%m_%d\")\n",
        "# renamed_sheet_name = f\"{original_sheet_name}_{date_str}\"\n",
        "\n",
        "# # Load the workbook and rename the sheet if it exists\n",
        "# workbook = load_workbook(file_path)\n",
        "\n",
        "# if original_sheet_name in workbook.sheetnames:\n",
        "#     # Rename the existing sheet\n",
        "#     sheet = workbook[original_sheet_name]\n",
        "#     sheet.title = renamed_sheet_name\n",
        "#     sheet.sheet_state = 'hidden'  # Hide the sheet\n",
        "\n",
        "# # Save the workbook after renaming and hiding the sheet\n",
        "# workbook.save(file_path)\n",
        "\n",
        "# # Write the new data to the original sheet name\n",
        "# with pd.ExcelWriter(file_path, mode='a', engine='openpyxl') as writer:\n",
        "#     df_me.to_excel(writer, sheet_name=original_sheet_name, index=False)"
      ],
      "metadata": {
        "id": "Cdtw_s6B0dQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# original_sheet_name = \"SOE24-25\"\n",
        "\n",
        "# # Get the current date to use in the renamed sheet name\n",
        "# date_str = datetime.now().strftime(\"%Y_%m_%d\")\n",
        "# renamed_sheet_name = f\"{original_sheet_name}_{date_str}\"\n",
        "\n",
        "# # Load the workbook and rename the sheet if it exists\n",
        "# workbook = load_workbook(file_path)\n",
        "\n",
        "# if original_sheet_name in workbook.sheetnames:\n",
        "#     # Rename the existing sheet\n",
        "#     sheet = workbook[original_sheet_name]\n",
        "#     sheet.title = renamed_sheet_name\n",
        "#     sheet.sheet_state = 'hidden'  # Hide the sheet\n",
        "\n",
        "# # Save the workbook after renaming and hiding the sheet\n",
        "# workbook.save(file_path)\n",
        "\n",
        "# # Write the new data to the original sheet name\n",
        "# with pd.ExcelWriter(file_path, mode='a', engine='openpyxl') as writer:\n",
        "#     df_bank_match_soe.to_excel(writer, sheet_name=original_sheet_name, index=False)\n"
      ],
      "metadata": {
        "id": "wL6VQgTX003X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# original_sheet_name = \"ME24-25\"\n",
        "\n",
        "# # Get the current date to use in the renamed sheet name\n",
        "# date_str = datetime.now().strftime(\"%Y_%m_%d\")\n",
        "# renamed_sheet_name = f\"{original_sheet_name}_{date_str}\"\n",
        "\n",
        "# # Load the workbook and rename the sheet if it exists\n",
        "# workbook = load_workbook(file_path)\n",
        "\n",
        "# if original_sheet_name in workbook.sheetnames:\n",
        "#     # Rename the existing sheet\n",
        "#     sheet = workbook[original_sheet_name]\n",
        "#     sheet.title = renamed_sheet_name\n",
        "#     sheet.sheet_state = 'hidden'  # Hide the sheet\n",
        "\n",
        "# # Save the workbook after renaming and hiding the sheet\n",
        "# workbook.save(file_path)\n",
        "\n",
        "# # Write the new data to the original sheet name\n",
        "# with pd.ExcelWriter(file_path, mode='a', engine='openpyxl') as writer:\n",
        "#     df_bank_match_me.to_excel(writer, sheet_name=original_sheet_name, index=False)\n"
      ],
      "metadata": {
        "id": "gT4-ol_G09am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_summary_all_bank_soe_due.to_excel(\"/content/drive/My Drive/2024_25/daybook.xlsx\",sheet_name='SOE_overview')\n",
        "\n",
        "# with pd.ExcelWriter(\"/content/drive/My Drive/2024_25/daybook.xlsx\",mode='a') as writer:\n",
        "#   df_soe.to_excel(writer,sheet_name='SOE_raw_xml')\n",
        "# with pd.ExcelWriter(\"/content/drive/My Drive/2024_25/daybook.xlsx\",mode='a') as writer:\n",
        "#   df_summary_all_bank_me_due.to_excel(writer,sheet_name='ME_overview')\n",
        "# with pd.ExcelWriter(\"/content/drive/My Drive/2024_25/daybook.xlsx\",mode='a') as writer:\n",
        "#   df_me.to_excel(writer,sheet_name='ME_raw_xml')"
      ],
      "metadata": {
        "id": "z2pbRc4CEuV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u_HZlR-_t762"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}